<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Machine Learning nano-degree notebook (Unsupervised Learning)</title>
  <meta name="description" content="Udacity machine learning nano-degree notebook.">

  <!-- CSS files -->
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/main.css">

  <link rel="canonical" href="/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2">
  <link rel="alternate" type="application/rss+xml" title="Neverland" href=" /feed.xml " />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="/favicon.png">
</head>


<body>
  
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <img src="/img/avatar.jpg" alt="" class="avatar">
  
  <a href="/" class="author_name">ZHENG ZHOU</a>
  <span class="author_job">Student (Master of Science)</span>
  <span class="author_bio mbm">I am undating myself...</span>
  <nav class="nav">
    <ul class="nav-list">
         
      <li class="nav-item">
        <a href="/archive/">Archive</a>
        <span>/</span>
      </li>
          
      <li class="nav-item">
        <a href="/categories/">Categories</a>
        <span>/</span>
      </li>
            
      <li class="nav-item">
        <a href="/tags/">Tags</a>
      </li>
       
    </ul>
  </nav>
  <div class="social-links">
  <ul>
    <li><a href="mailto:encorechow1992@gmail.com" class="social-link-item" target="_blank"><i class="fa fa-fw fa-envelope"></i></a></li>
    
    <li><a href="http://facebook.com/axieandyangyang" class="social-link-item" target="_blank"><i class="fa fa-fw fa-facebook"></i></a></li>
    
    <li><a href="http://linkedin.com/in/zhou-zheng-378041a5" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    
    <li><a href="http://github.com/encorechow" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

  <nav class="nav">
  <ul class="nav-list">
    <li class="nav-item">
      <a href="/aboutme/">About Me</a>
    </li>
  </ul>
</nav>

</div>

      </div>
    </div>

    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "/" >
  Home
</a>

<div class="post-image-feature">
  <img class="feature-image" src=
  
  "/img/ml-pic.jpg"
  
  alt="Machine Learning nano-degree notebook (Unsupervised Learning) feature image">

  
</div><!-- /.image-wrap -->


<div id="post">
  <header class="post-header">
    <h1 title="Machine Learning nano-degree notebook (Unsupervised Learning)">Machine Learning nano-degree notebook (Unsupervised Learning)</h1>
    <span class="post-meta">
      <span class="post-date">
        21 NOV 2016
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    2 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h1 id="unsupervised-learning">Unsupervised Learning</h1>

<h2 id="clustering">1. Clustering</h2>

<p><a href="http://scikit-learn.org/stable/modules/clustering.html">Sklearn Clustering Algorithm Interface</a></p>

<h4 id="single-linkage-clustering">1.1. Single Linkage Clustering</h4>
<p>The simplest clustering which has following features:</p>

<ul>
  <li>consider each object a cluster (n objects).</li>
  <li>define inter-cluster distance as the distance between the closest two points in the two clusters. (Can be average or farthest two points, they have different name)</li>
  <li>merge two closest clusters</li>
  <li>repeat <script type="math/tex">n-k</script> times to make k clusters</li>
</ul>

<p>This gives us a hierarchical agglomerative tree structure.</p>

<h4 id="soft-clustering">1.2. Soft Clustering</h4>

<p>Instead of finding out which data point belongs to which cluster like k-mean algorithm, in soft clustering, we will try to find out what the probability of a specific data point belongs to some hypothesis (which is the mean of some gaussian).</p>

<p>Assume the data was generate by:</p>

<ol>
  <li>Select one of K gaussians (with fixed k means and variance) uniformly (So the prior can be ignored)</li>
  <li>Sample <script type="math/tex">X_i</script> from that gaussian</li>
  <li>Repeat n times</li>
</ol>

<p>Task: Find a hypothesis <script type="math/tex">% <![CDATA[
h = <\mu_1,...,\mu_k> %]]></script> that maximize the probability of the data (Maximum likelihood)</p>

<p>P.S. Hidden variable is the variables that are inferred from other observed variables</p>

<h4 id="expectation-maximization">1.2 Expectation Maximization</h4>

<p><strong>Expectation (define Z from <script type="math/tex">\mu</script> and it is soft clustering, analogy of assigning data to the cluster in K-mean algorithm):</strong></p>

<script type="math/tex; mode=display">\mathbf{E}[Z_{i,j}] = \frac{P(x=x_i|\mu=\mu_j)}{\sum_{i=1}^{k} P(x=x_i|\mu=\mu_j)}</script>

<p><script type="math/tex">Z_{i,j}</script> stands for the probability of observed <script type="math/tex">x_i</script> produced by the gaussian with <script type="math/tex">\mu_j</script></p>

<p>Additionally:</p>

<script type="math/tex; mode=display">P(x=x_i|\mu=\mu_j) = e^{-\frac{1}{2}\sigma^2(x_i-\mu_i)^2}</script>

<p><strong>Maximization (define <script type="math/tex">\mu</script> from Z, analogy of computing mean each iteration in K-mean algorithm)</strong></p>

<script type="math/tex; mode=display">\mu_{j} = \frac{\sum_i \mathbf{E}[Z_{i,j}]x_i}{\sum_{i} \mathbf{E}[Z_{i,j}]}</script>

<p>This can be transformed to K-mean algorithm if cluster assignments use argmax (which ends up with only 0 and 1, 0 stands for not belonging to that class and 1 otherwise).</p>

<p><strong>Properties of EM:</strong></p>

<ul>
  <li>monotonically non-decreasing likelihood</li>
  <li>does not converge (practically does)</li>
  <li>will not diverge</li>
  <li>can get stuck (can randomly restart)</li>
  <li>works with any distribution (if E (Bayes net stuff), M (Counting things) solvable)</li>
</ul>

<h4 id="clustering-properties">1.3. Clustering Properties</h4>

<ul>
  <li>Richness<br />
For any assignment of objects to clusters, there is some distance matrix D such that <script type="math/tex">P_D</script> return that clustering <script type="math/tex">\forall \space C \space \exists D P_D=C</script></li>
  <li>
    <p>Scale-invariance<br />
Scaling distance by a positive value does not change the clustering <script type="math/tex">\forall D \space \forall K>0 P_D = P_{KD}</script></p>
  </li>
  <li>Consistency<br />
Shrinking intra-cluster distances and expanding inter-cluster distances does not change the clustering <script type="math/tex">P_D = P_{D^{'}}</script></li>
</ul>

<p>So what consistency says is if you found that a bunch of things were similar, and a bunch of other things were dissimilar, that if you made the things that were similar more similar, and the things that were not similar less similar, it shouldn’t change your notion which things are similar and which things are not.</p>

<h4 id="impossibility-theorem">1.4. Impossibility Theorem</h4>

<p>No clustering schema can achieve all above three properties. These three properties are mutually contradiction in a sense. (Proven by Kleinberg)</p>

<h4 id="summary">Summary</h4>

<ul>
  <li>Clustering</li>
  <li>Connection to compact description</li>
  <li>Algorithm
    <ul>
      <li>K-means</li>
      <li>SLC (terminates fast)</li>
      <li>EM (soft clusters)</li>
    </ul>
  </li>
  <li>Clustering properties &amp; impossibility</li>
</ul>

<p><em>————————————————————————————— Updating… Nov. 30, 2016</em></p>

<h2 id="feature-engineering">2. Feature Engineering</h2>

  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=/articles/2016-11/Machine-Learning-Nanodegree-Notebook-2" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->



        <footer>
  &copy; 2016 ZHENG ZHOU. Powered by <a href="http://jekyllrb.com/">Jekyll</a>
</footer>

      </div>
    </div>

  </div>
  <script type="text/javascript" src="/js/jquery-2.1.4.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="https://d3js.org/d3.v4.min.js"></script>

</script>


</body>
</html>
